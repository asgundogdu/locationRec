{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from CF.collaborative_filtering import locationRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train shape (4102336, 3)\n",
      " validation shape (1849592, 3)\n",
      " test shape (1941760, 3)\n",
      "4712 21347\n"
     ]
    }
   ],
   "source": [
    "recmodel = locationRec()\n",
    "recmodel.datapipeline(preproccesing=2)\n",
    "# all_df = pd.concat([recmodel.train, recmodel.validate, recmodel.test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = recmodel.train.user_nickname.tolist()\n",
    "items = recmodel.train.town.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Items: 4712, #Users: 21347\n"
     ]
    }
   ],
   "source": [
    "num_items = len(set(items))\n",
    "num_users = len(set(users))\n",
    "print(\"#Items: {}, #Users: {}\".format(num_items, num_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "epochs = 100\n",
    "batch_size = 250\n",
    "num_input = num_items   # num of items\n",
    "num_hidden_1 = 15       # 1st layer num features\n",
    "num_hidden_2 = 10 # 2nd layer num features (the latent dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float64, [None, num_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "# Building the decoder\n",
    "\n",
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "y_pred = decoder_op\n",
    "y_true = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer, minimize the squared error\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.1).minimize(loss)\n",
    "\n",
    "predictions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = recmodel.user_item_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21347, 4712)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()\n",
    "save_dir = \"./model/cf_tf/\"\n",
    "i_global=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)\n",
    "sess.run(local_init)\n",
    "train_writer = tf.summary.FileWriter(save_dir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = int(matrix.shape[0] / batch_size)\n",
    "matrix = np.array_split(matrix, num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i)\n",
    "    avg_cost = 0\n",
    "\n",
    "    for batch in matrix:\n",
    "        _, l = sess.run([optimizer, loss], feed_dict={X: batch})\n",
    "        avg_cost += l\n",
    "\n",
    "    avg_cost /= num_batches\n",
    "\n",
    "    print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()\n",
    "save_dir = \"./model/cf_tf/\"\n",
    "i_global=0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "    train_writer = tf.summary.FileWriter(save_dir, session.graph)\n",
    "\n",
    "    num_batches = int(matrix.shape[0] / batch_size)\n",
    "    matrix = np.array_split(matrix, num_batches)\n",
    "\n",
    "    for i in range(20):\n",
    "\n",
    "        avg_cost = 0\n",
    "\n",
    "        for batch in matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "        # if i % display_step == 0 or i == 1:\n",
    "        #     print('Step %i: Minibatch Loss: %f' % (i, l))\n",
    "        \n",
    "    summary = tf.Summary(value=[\n",
    "            tf.Summary.Value(tag=\"loss/test\", simple_value=avg_cost),])\n",
    "        \n",
    "    train_writer.add_summary(summary, i_global)\n",
    "\n",
    "    saver.save(session, save_path=save_dir, global_step=i_global)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions...\")\n",
    "\n",
    "    matrix = train.values\n",
    "    \n",
    "    preds = session.run(decoder_op, feed_dict={X: matrix})\n",
    "\n",
    "    print(matrix.shape)\n",
    "    print(preds.shape)\n",
    "\n",
    "    predictions = predictions.append(pd.DataFrame(preds))\n",
    "\n",
    "    predictions = predictions.stack().reset_index(name='rating')\n",
    "    predictions.columns = ['user_nickname', 'town', 'checkins']\n",
    "    predictions['user_nickname'] = predictions['user_nickname'].map(lambda value: users[value])\n",
    "    predictions['town'] = predictions['town'].map(lambda value: items[value])\n",
    "\n",
    "    #print(predictions.shape)\n",
    "\n",
    "    print(\"Filtering out items in training set\")\n",
    "\n",
    "    keys = ['user_nickname', 'town']\n",
    "    i1 = predictions.set_index(keys).index\n",
    "    i2 = recmodel.user_item_network_training.CF_data.set_index(keys).index\n",
    "\n",
    "    recs = predictions[~i1.isin(i2)]\n",
    "    recs = recs.sort_values(['user_nickname', 'Rating'], ascending=[True, False])\n",
    "    recs = recs.groupby('user_nickname').head(k)\n",
    "    recs.to_csv('recs.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "    test = recmodel.user_item_network_training.CF_data\n",
    "    test = test.sort_values(['user_nickname', 'Rating'], ascending=[True, False])\n",
    "\n",
    "    print(\"Evaluating...\")\n",
    "\n",
    "    p = 0.0\n",
    "    for user in users[:10]:\n",
    "        test_list = test[(test.User == user)].head(k).as_matrix(columns=['Movie']).flatten()\n",
    "        recs_list = recs[(recs.User == user)].head(k).as_matrix(columns=['Movie']).flatten()\n",
    "\n",
    "        #session.run(pre_op, feed_dict={eval_x: test_list, eval_y: recs_list})\n",
    "\n",
    "        pu = precision_score(test_list, recs_list, average='micro')\n",
    "        p += pu\n",
    "\n",
    "        print(\"Precision for user {}: {}\".format(user, pu))\n",
    "        print(\"User test:--\\n{}\".format([mov_dict[x][1] for x in test_list]))\n",
    "        print(\"User recs:--\\n{}\".format([mov_dict[x][1] for x in recs_list]))\n",
    "        print()\n",
    "    p /= 10#len(users)\n",
    "\n",
    "    #p = session.run(pre)\n",
    "    print(\"Precision@{}: {}\".format(k, p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
